### 关于 wx-tmy-prompt

本项目由微信公众号 “填密语” 官方提供，主要用来定义填密语公众号所对接 chatGPT 聊天室的规格。

填密语公众号是一个多聊天室机器人问答系统，公众号里设置多个房间（room），不同房间提供不同主题的问答服务。每个 room 定义若干触发词（magics），一个触发词对应一项动作，一项动作既包括发起与 chatGPT 一次问答，也包括触发修改 room 配置。

&nbsp;

### 快速入门

第一步：用户先关注微信公众号 “填密语”，不妨在微信中搜索 “填密语”，找到并成功关注后，系统将自动创建两个房间：“GPT” 与 “中英互译”。用户在公众号中点 “主页” 及 “配置” 按钮，系统将跳至指导初学者如何使用的页面。

第二步：进入本公众号的 “GPT” 房间，将如下二维码拍照（如果当前您正用手机访问本网页，将如下二维码截屏也是可以的），然后把照片或截屏在公众号（当前 GPT 房间）发送到公众号后台，系统随即自动导入 room 定义。

（图片）

第三步，在公众号中输入 "？"，您将发现 “可换房间” 列表多了一项 “旅游服务” ，这正是上面二维码指向的 room 定义。切换到这个新增的房间后，输入 "介绍 广东梁启超故居"，chatGPT 将立即返回一段关于 “梁启超故居” 景点的介绍文字。

上面扫二维码实质是将本项目中 "sample_prompt_v1.json" 文件 URL 地址提交给公众号，这个 json 文件定义了旅游服务 room 规格。

&nbsp;

### 自定义聊天室

下文介绍如何自定义一间可在填密语公众号中使用的聊天室，拿上面介绍的旅游服务举例。

先讲最简情形，比方，如何用户只查询某景点的扼要介绍，定义 room 如下：

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "magic_rules": {
    "介绍":[["景点名","set","{where}"]]
  },
  "prompts": {
    "介绍":{"ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。"}
  },
  "hint_magics": ["介绍"]
}
```

这里，room_ver 是填密语公众号要求的 room 规格版本号，当前固定填 1，以后若有更高版本规格推出，可以改填 "2, 3" 等，官方发布的 room_ver 版本，将在本公号维持后向兼容。

room_desc 是聊天室名称，当输入类似 "换房间 旅游服务" 指令时，会用到 room_desc。

system_role 指定聊天机器人将要扮演的角色。

magic_rules 定义聊天指令触发词，常规聊天内容通常不会以 `<触发词> `（即，一个触发词后跟空格）的格式开头，所以，与机器人正常一问一答聊天与给机器人下发特定指令之间有明显差别，系统能准确区分他们。

触发词就像一句魔咒，你喊一声，魔咒匹配后，机器人随即执行你预设的指令。如上面例子，我们定义了一个触发词 "介绍"，触发后，系统最终向 chatGPT 发送在 prompts 预定义的一句问话。magic_rules 配置项定义触发词的参数规格，比如上面例子，触发词 "介绍" 只定义一个参数 "景点名"，用户输入 `"介绍 广东梁启超故居"`，系统就自动识别出 "景点名" 参数，赋其值为 "广东梁启超故居"，这个值将赋给 `{where}` 局部变量，以便 prompt 引用它，形成特定格式的一句问话。

prompts 定义各触发词所对应的 prompt 字串，本例子中，将 `{where}` 变量代入，输入"介绍 广东梁启超故居" 后产生的 prompt 字串就是 “我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：广东梁启超故居。” 

hint_magics 罗列可打印输出的触发词列表，在用户输入 "?" 后打印的帮助信息中显示。本例打印信息如下：

```
当前房间：旅游服务

当前指令：
  介绍 景点名
```

在 magic_rules 中定义触发词都有捕获并触发动作的能力，但并不是所有触发词都在 hint_magics 列出，未列出的触发词缺少规格提示（用户输入 "？" 后无提示），这类触发词很像咒语，普通人不知道咋用，其用法被隐藏了，只有修成大法的人才用得出来。

&nbsp;

### 指定机器人的温度与上下文深度

chatGPT 的温度参数（temperature）用来控制 AI 应答的发散程度，在 0 至 2 之间取值 0 到 2 这间取值，取值越低，AI 回答越倾向于高概率答案，即，回答越确定，取值越高，越不确定，甚至胡言乱语，但更具创造性。

chatGPT 还是边聊边忘的机器人，你提供给它的上文信息越多，它的表现更像真人，能做到前后句上下文连贯，但传递给它的历史记录总数有上限，否则与它聊天成本很高，输入 token 比输出 token 稍稍便宜。我们把每次提交问题时，附带传给 AI 的最近问答次数叫上下文深度（context_size），填密语公众号建议的平均取值是 5，即，让机器人记忆最近的 5 问 5 答。

如果当前问话不依赖历史记录，我们不妨将上下文深度设为 0，即，不再向 chatGPT 提交历史沟通信息，这样能大幅节约聊天成本。

我们继续优化上面的例子，增加几个配置项。

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。",
      "context_size":3, "temperature":0
    }
  },
  "hint_magics": ["介绍"]
}
```

我们可以看到，room 定义的 context_size 与 temperature 缺省值分别是 `1` 与 `0.7`，缺省值还可以被 prompts 中某具体触发词的 prompt 定义覆盖，本例 "介绍" 触发词的 prompt 定义用 3 与 0 值分别替代 context_size 与 temperature 缺省值。

max_tokens 配置项指示本 room 一次问答限用 600 tokens，遇到可能超出的情况 chatGPT 会截断返回的文本。

补充说明一下，上面我们还为 "介绍" 触发词增加第二个参数  `*`，星号表示匹配余下的所有输入文本，这些文本将添加到对应 prompt 的尾部。比如，用户输入 “介绍 广东梁启超故居 在深圳怎么坐车？”，最终获得的输入是：“我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：广东梁启超故居。在深圳怎么坐车？”

&nbsp;

### 给 room 设置全局变量

现在我们增加第二个触发词 “特产”，让 AI 介绍景点有什么特产，但希望不要让用户再输一次景点名称。

把 room 定义优化成如下样子（增加了 “特产” 触发词的相关定义）：

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "globals": {"where":"北京故宫"},
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"],
    "特产":["*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。",
      "context_size":3, "temperature":0
    },
    "特产":{ "ask":"请问 {where} 景点有什么特产？", "context_size":5, "temperature":0}
  },
  "hint_magics": ["介绍","特产"]
  "state_desc": "({where})"
}
```

前面我们已介绍局部变量 `{where}`，现在把该 local 变量改成 global 全局变量，便于让同一 room 中由不同触发词生成的 prompt 都能引用这变量，变量赋值后可被多次引用。只需将 `"{where}"` 定义纳入 globals 配置项，这个原先是 local 的变量就变 global 了。

当全局变量被修改（比如输入 "介绍 香港迪斯尼乐园"，where 变量就改了）时，公众号后台服务器会自动保存修改后的值，但对局部变量则不保存。凡引用的变量未在 room 的 globals 列表申明的，都是局部变量。局部变量只在一次触发词的触发过程中有效，当次一问一答结束 local 变量随即失效。

用户输入 "?" 查询时，宜在打印帮助信息指示全局变量当前取值。我们只需在 state_desc 配置项引用相应变量。在这个例子中，输入 "？" 后的打印信息如下：

```
当前房间：旅游服务(广东梁启超故居)

当前指令：
  介绍 景点名 *
  特产 *
```

前面我们已介绍字串类型的变量，这类变量要用 set 指令实现赋值。除了字串类型，global 与 local 变量还支持：布尔、数值、列表等类型，详情在后文 “规则引擎” 介绍。

&nbsp;

### 启发式聊天

由于 LLM 模型的应用特点，我们与 AI 聊天时，如果前置插入若干问答范例，AI 会有更优表现。现在，我们为 “旅游服务” 再增加一个 “翻译” 触发词，将前置若干问答。

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "globals": {"where":"北京故宫"},
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"],
    "特产":["*"],
    "翻译":["*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。", "context_size":3, "temperature":0 },
    "特产":{ "ask":"请问 {where} 景点有什么特产？", "context_size":5, "temperature":0},
    "翻译":{ "prefix": [
      {"ask":"我希望你同时扮演中文翻译、拼写纠正和改进者角色。我会以任何语言与你交谈，你会检测语言，翻译它，并用更为优美、高雅的高级中文词汇和句子来回答我的文本，保持意义相同，但使它们更具文学性，请只回复更正和改进，不要写解释。","answer":"好的"}, 
      {"ask":"istanbulu cok seviyom burada olmak cok guzel","answer":"我非常喜欢伊斯坦布尔，在这里很愉快。"}],
      "ask":"",
      "max_tokens":1000, "temperature":1.2,
      "context_size":0, "reset_context":true
    }
  },
  "hint_magics": ["介绍","特产","翻译"],
  "state_desc": "({where})"
}
```

上述 prompts 的 "翻译" 项定义的 prefix 是前置若干问答，此外还我们指定 temperature 为 `1.2`，让 AI 回答更有创意，再指定 reset_context 为 true，表示此前的历史聊天将被忽略，设置 context_size 为 0，指示紧接本次问答之后的聊天，记忆深度为 0，即，不上传历史记录。

比方用户输入："翻译 ヒグマとの危険な遭遇を避けてもらおうと、北海道警函館方面本部がクマの出没情報をまとめた管内の地図を作り、ウェブサイトで公表している。"，AI 将响应："为了避免与棕熊发生危险的接触，北海道警察函馆方面本部已制作了棕熊出没信息地图并在网上公布 "。本处举例只为了方便讲解，其实更适合旅游的翻译服务，可能是拍照上传，由 AI 从图中识别外国文字，然后优雅的翻译成本国语言。

我们为 "特产" 触发词指定的 context_size 为 5，便于在 AI 答复景点有什么特产后，用户可以接着按常规聊天方式，比方进一步询问各类特产详情。而指定 "翻译" 触发词的 context_size 为 0，是不希望在翻译之后继续聊天。

&nbsp;
