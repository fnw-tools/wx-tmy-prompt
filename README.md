### 关于 wx-tmy-prompt

本项目由微信公众号 “填密语” 官方提供，主要用来定义填密语公众号对接 chatGPT 聊天室的 prompt 规格。

填密语公众号是一个多聊天室机器人问答系统，公众号里设置多个房间（room），不同房间提供不同主题的问答服务。本项目定义聊天室 room 的规格，一个 room 中可定义多个触发词 magics，每个触发词都对应一项动作，动作包括发起与 chatGPT 聊天会话，也包括修改 prompt 配置。

&nbsp;

### 快速入门

第一步：关注微信公众号 “填密语”，可以在微信中搜索找到。关注成功后，系统会自动为您创建两个房间：“GPT” 与 “中英互译”，在公众号中点 “主页” 及 “配置” 按钮系统将跳到相关页指导初学者如何使用本工具。

第二步：进入本公众号的 “GPT” 房间，将如下二维码拍照（如果当前您正用手机访问本网页，将下面二维码截屏），然后把照片或截屏图片在公众号中发送。公众号随即自动导入一个 room 定义。

（图片）

第三步，在公众号中输入 "？"，您将发现 “可换房间” 列表多了一项 “旅游服务” ，切换到新增的房间后，输入 "介绍 广东梁启超故居"，chatGPT 将响应一段关于 “梁启超故居” 景点的介绍文字。

上面扫二维码实质是将本项目的 "sample_prompt_v1.json" 文件 URL 地址告诉公众号，这个 json 文件正是 “旅游服务” 的 room 定义。

&nbsp;

### 自定义聊天室

下文介绍如何自定义一间可在填密语公众号中使用的聊天室，拿上面介绍的旅游服务举例。

先讲最简情形，比方，如何用户只查询某景点的扼要介绍，定义 room 如下：

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "magic_rules": {
    "介绍":[["景点名","set","{where}"]]
  },
  "prompts": {
    "介绍":{"ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。"}
  },
  "hint_magics": ["介绍"]
}
```

这里，room_ver 是填密语公众号要求的 room 规格版本号，当前固定填 1，以后若有更高版本规格推出，可以改填 "2, 3" 等，官方发布的历代 room_ver 版本，在本公众号将维持后向兼容。

room_desc 是聊天室名称，输入类似 "换房间 旅游服务" 指令时，会用到 room_desc。

system_role 指定聊天机器人扮演的角色。

magic_rules 定义聊天指令触发词，聊天内容通常不会以 `<触发词> `（即，一个触发词后跟空格）开头，所以，与机器人正常聊天与给机器人发 “触发词指令” 能正确被系统区分。触发词就像一句魔咒，你喊一声，咒语匹配后，机器人随即执行你预设的指定。上面例子中，我们定义了一个触发词 "介绍"，触发后，系统将发送在 prompts 预定义的一句问话。magic_rules 定义触发词的参数规格，比方上面例子，触发词 "介绍" 定义一个参数 "景点名"，用户输入 "介绍 广东梁启超故居"，系统就自动识别出景点名参数，其值为 "广东梁启超故居"，这个值将赋给 `{where}` 局部变量，以便 prompt 可以引用它。

prompts 定义各触发词所对应的 prompt 字串，在这个例子中，将 `{where}` 变量代入，输入"介绍 广东梁启超故居" 后产生的 prompt 字串就是 “我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：广东梁启超故居。” 

hint_magics 则罗列可打印输出的触发词列表，在用户输入 "?" 后打印的帮助信息中显示。本例打印信息为：

```
当前房间：旅游服务

当前指令：
  介绍 景点名
```

在 magic_rules 中定义触发词都有捕获并触发动作的能力，但并不是所有触发词都在 hint_magics 中列出，未列出的触发词缺少规格提示（用户输入 "？" 后不打印提示），这类触发词很像咒语，普通人不知道咋用，用法被隐藏了，只有修成大法的人才用得出来。

&nbsp;

### 指定机器人的温度与记忆深度

chatGPT 的温度参数用来控制 AI 应答的发散程度，在 0 至 2 之间取值 0 到 2 这间取值，取值越低，AI 回答越倾向于高概率答案，即，回答越确定，取值越高，越不确定，甚至胡言乱语，但更具创造性。

chatGPT 还是边聊边忘的机器人，你提供给它的上文信息越多，它的表现更像真人，能做到前后句上下文连贯，但传递给它的历史记录总数有上限，否则与它聊天成本很高，输入 token 只比输出 token 便宜一点。我们把每次提交问题时，附带传给 AI 的最近问答次数叫记忆深度，填密语公众号建议的平均取值是 5，即，让机器人记忆最近 5 问 5 答。

如果问话完全不依赖历史问答，不妨将记忆深度设为 0，对节约聊天成本有利。

我们继续优化上面的例子。

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "memory_deep": 1,
  "temperature": 0.7,
  "max_token": 600,
  
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。", "memory_deep":3, "temperature":0 }
  },
  "hint_magics": ["介绍"]
}
```

我们可以看到，这里 room 定义了缺省的 memory_deep 与 取值分别是 `1` 与 `0.7`，缺省值可以被 prompts 中具体某个触发词的定义覆盖。

上面 max_token 配置项指示本 room 一次问答限用 600 token，遇到要超的情况 AI 会截断返回的文本。

上面我们还为 "介绍" 触发词增加第二个参数  `*`，星号表示余下的所有输入，这些输入将添加到对应 prompt 的尾部。比如，用户输入 “介绍 广东梁启超故居 怎么坐车？”，最终获得的输入是：“我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：广东梁启超故居。怎么坐车？”

&nbsp;

### 给 room 设置全局变量

现在我们增加第二个触发词 “特产”，但不希望让用户再输一遍景点名称。

将 room 定义优化成如下样子：

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "memory_deep": 1,
  "temperature": 0.7,
  "max_token": 600,
  
  "globals": {"where":"北京故宫"},
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"],
    "特产":["*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。", "memory_deep":3, "temperature":0 },
    "特产":{ "ask":"请问 {where} 景点有什么特产？", "memory_deep":5, "temperature":0}
  },
  "hint_magics": ["介绍","特产"]
  "state_desc": "({where})"
}
```

前面已介绍的 local 局部变量 `{where}`，在这里改成 global 全局变量，便于让相同 room 中经不同触发词生成的 prompt 都能引用该变量。

全局变量有变化时，公众号服务器会自动保存，局部变量则不保存。引用的变量若未在 room 的 globals 列表指明的，都是局部变量。局部变量只在一次触发词触发，并生成 prompt 时起作用，当次用完随即失效。

全局变量应该在用户输入 "?" 查询时，打印出信息指明变量当前值，我们只需在 state_desc 配置项引用变量。这个例子中，输入 "?" 后的打印信息如下：

```
当前房间：旅游服务(广东梁启超故居)

当前指令：
  介绍 景点名 *
  特产 *
```

本节已举例字串类型的变量，这类变量用 set 指令赋值。除了字串类型，global 与 local 变量还支持：布尔、数值、列表等类型，详情在后文介绍。

&nbsp;

### 启发式聊天

由 LLM 模型的应用特点，与 AI 聊天时，如果前置插入若干问答范例，AI 将表现更佳。现在我们为 “旅游服务” 再增加一项 “翻译” 触发词，前置若干问答。

``` json
{
  "room_ver": 1,
  "room_desc": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "memory_deep": 1,
  "temperature": 0.7,
  "max_token": 600,
  
  "globals": {"where":"北京故宫"},
  "magic_rules": {
    "介绍":[["景点名","set","{where}"], "*"],
    "特产":["*"],
    "翻译":["*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。", "memory_deep":3, "temperature":0 },
    "特产":{ "ask":"请问 {where} 景点有什么特产？", "memory_deep":5, "temperature":0},
    "翻译":{"prefix":[{"ask":"我希望你同时扮演中文翻译、拼写纠正和改进者角色。我会以任何语言与你交谈，你会检测语言，翻译它，并用更为优美、高雅的高级中文词汇和句子来回答我的文本，保持意义相同，但使它们更具文学性，请只回复更正和改进，不要写解释。","answer":"好的"}, {"ask":"istanbulu cok seviyom burada olmak cok guzel","answer":"我非常喜欢伊斯坦布尔，在这里很愉快。"}],"ask":"","temperature":1.2, "pre_clear":true}
  },
  "hint_magics": ["介绍","特产","翻译"],
  "state_desc": "({where})"
}
```

上述 prompts 中 "翻译" 一项中定义 prefix 是前置的若干问答，同时我们还指定 temperature 为 `1.2`，让 AI 回答更有创意，设置 pre_clear 为 true，表示此前的历史聊天记录将被忽略，相当于先清历史问答，然后开始本次聊天。

&nbsp;
